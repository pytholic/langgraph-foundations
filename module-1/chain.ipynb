{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 concepts.\n",
    "\n",
    "* Using [chat messages](https://docs.langchain.com/oss/python/langchain/messages) as our graph state\n",
    "* Using [chat models](https://docs.langchain.com/oss/python/integrations/chat) in graph nodes\n",
    "* [Binding tools](https://docs.langchain.com/oss/python/langchain/models#tool-calling) to our chat model\n",
    "* [Executing tool calls](https://docs.langchain.com/oss/python/langchain/models#tool-execution-loop) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_google_genai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [messages](https://docs.langchain.com/oss/python/langchain/messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Pytholic\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Pytholic\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Pytholic\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Pytholic\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Chat Models\n",
    "\n",
    "Chat models use a sequence of messages as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://docs.langchain.com/oss/python/integrations/chat) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `GOOGLE_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9026bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='That\\'s a fantastic question! When it comes to seeing Orcas in the US, there are two primary contenders for the \"best\" place, each offering a slightly different experience:\\n\\n1.  **The San Juan Islands, Washington (Salish Sea):**\\n    *   **Why it\\'s often considered the #1 spot:** This area, encompassing the waters around Friday Harbor, San Juan Island, and the broader Puget Sound/Salish Sea, is historically famous for its **Southern Resident Killer Whales** (J, K, and L Pods). These are fish-eating Orcas that traditionally spend significant time here during the summer months, feeding on Chinook salmon.\\n    *   **Current Situation:** While the Southern Residents are endangered and their numbers are low, making *their* sightings less frequent and reliable than in the past, the good news is that **Bigg\\'s (transient) Killer Whales** are increasingly common and reliable in the Salish Sea. These are mammal-eating Orcas that hunt seals, sea lions, and porpoises, and they are thriving. Many tours now focus on finding these active and exciting transient pods.\\n    *   **Best Time to Go:** Late spring through early fall (May to September) offers the most consistent sightings and best weather. July and August are peak season.\\n    *   **Departure Points:** Most tours depart from Friday Harbor (San Juan Island), Orcas Island, Anacortes, or Seattle.\\n    *   **Experience:** You\\'ll be surrounded by beautiful islands, often seeing other wildlife like seals, sea lions, and bald eagles.\\n\\n2.  **Alaska (Various Regions):**\\n    *   **Why it\\'s excellent:** Alaska\\'s vast and nutrient-rich waters support a large and healthy population of Orcas, both resident (fish-eating) and transient (mammal-eating). While not as famous for specific named pods as the Salish Sea, the sheer abundance of marine life often translates to excellent Orca sightings.\\n    *   **Key Locations:**\\n        *   **Kenai Fjords National Park (near Seward):** Known for its dramatic glaciers and abundant wildlife, including Orcas, humpback whales, and sea otters.\\n        *   **Prince William Sound (near Valdez):** Another stunning area with glaciers and a healthy Orca population.\\n        *   **Southeast Alaska (Juneau, Sitka, Ketchikan):** Cruises and tours in these areas frequently encounter Orcas, especially during the summer salmon runs.\\n    *   **Best Time to Go:** Summer (June to August) is prime time for whale watching in Alaska, coinciding with the salmon runs and milder weather.\\n    *   **Experience:** You\\'ll get to see Orcas against a backdrop of breathtaking glaciers, towering mountains, and pristine wilderness. Alaska offers a wilder, more remote whale-watching experience.\\n\\n**Which one is \"best\" for you depends on what you\\'re looking for:**\\n\\n*   **For historical significance and a chance to see the famous (though now rare) Southern Residents, plus reliable Bigg\\'s Orcas, the San Juan Islands are your go-to.** It\\'s also more accessible from a major city (Seattle).\\n*   **For a wilder, more remote experience with a high chance of seeing Orcas among stunning glacial landscapes, Alaska is unbeatable.**\\n\\n**General Tips for Orca Watching:**\\n\\n*   **Go with a reputable tour operator:** They know the waters, the whales\\' habits, and adhere to responsible viewing guidelines (e.g., staying a respectful distance).\\n*   **Be patient:** Orcas are wild animals, and sightings are never guaranteed, but tour operators have excellent tracking networks.\\n*   **Dress in layers:** Even in summer, it can be cool and windy on the water.\\n*   **Bring binoculars and a good camera:** You\\'ll want to capture those moments!\\n\\nI\\'d personally recommend the **San Juan Islands** for its established infrastructure and high likelihood of seeing the active Bigg\\'s Killer Whales, especially if you\\'re looking for a dedicated Orca-focused trip within the continental US.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c23d8-c4fc-75f3-a79f-346d64f459fe-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 46, 'output_tokens': 1935, 'total_tokens': 1981, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1069}})\n"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 46,\n",
       " 'output_tokens': 1935,\n",
       " 'total_tokens': 1981,\n",
       " 'input_token_details': {'cache_read': 0},\n",
       " 'output_token_details': {'reasoning': 1069},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.5-flash',\n",
       " 'safety_ratings': [],\n",
       " 'model_provider': 'google_genai'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.usage_metadata | result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://docs.langchain.com/oss/python/integrations/chat) and [tool calling interface](https://blog.langchain.com/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"pytholic\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "532562f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (5054854d-5dc2-46c9-b2b1-ac5f660d9e29)\n",
      " Call ID: 5054854d-5dc2-46c9-b2b1-ac5f660d9e29\n",
      "  Args:\n",
      "    b: 3\n",
      "    a: 2\n"
     ]
    }
   ],
   "source": [
    "tool_call.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'b': 3, 'a': 2},\n",
       "  'id': '5054854d-5dc2-46c9-b2b1-ac5f660d9e29',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fef263",
   "metadata": {},
   "source": [
    "The above syntax is different from langchain where we use `@tool` decorator to define the tool and then pass it to `create_agent` function.\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = multiply.bind_tools()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\", temperature=0.0)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[tool1],\n",
    "    system_prompt=\"You are an arithmetic wizard. Use your tools to calculate the square root and square of any number.\"\n",
    ")\n",
    "\n",
    "question = HumanMessage(content=\"What is 2 multiplied by 3\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use  [messages](https://docs.langchain.com/oss/python/langchain/overview#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value will overwrite the prior `messages` value!\n",
    " \n",
    "As our graph runs, we want to **append** messages to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://docs.langchain.com/oss/python/langgraph/graph-api#reducers) to address this.\n",
    "\n",
    "Reducers specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built  [`MessagesState`](https://docs.langchain.com/oss/python/langgraph/graph-api#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='00249ae7-b903-45e9-85f3-ef6ab1479bc0', tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='0b2cde00-f499-4552-82f0-e4d8e907630c'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='c4afff09-1245-4cf1-8346-7ea78614c194', tool_calls=[], invalid_tool_calls=[])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass\n",
    " \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I am a large language model, able to perform various tasks. What can I do for you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (5f0aa741-506a-4edb-a19a-d06e4395c5e2)\n",
      " Call ID: 5f0aa741-506a-4edb-a19a-d06e4395c5e2\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067600eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

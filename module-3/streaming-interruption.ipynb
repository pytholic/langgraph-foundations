{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_google_genai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://docs.langchain.com/oss/python/langgraph/streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State)-> Literal [\"summarize_conversation\",END]:\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://docs.langchain.com/oss/python/langgraph/streaming#supported-stream-modes).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://docs.langchain.com/oss/python/langgraph/streaming#stream-graph-state) for graph state.\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Hi there, Pytholic! ðŸ‘‹\\n\\nThat's a fantastic self-description â€“ I love it! You're definitely in good company here. Python has a way of captivating us all with its versatility, readability, and vast ecosystem.\\n\\nSo, what kind of Python adventures are you currently on, or what brings you here today? Are you diving into data science, web development, automation, machine learning, or something else entirely?\\n\\nHow can I help you explore your Pytholic tendencies further?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c425e-1486-7b81-8d57-3f0edf5568ee-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 9, 'output_tokens': 1168, 'total_tokens': 1177, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1065}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm pytholic\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ah, welcome back, Pytholic! ðŸ‘‹\n",
      "\n",
      "It's great to hear from you again! That strong Python identity is definitely shining through.\n",
      "\n",
      "So, tell me, what's on your mind today? Are you looking to:\n",
      "\n",
      "*   **Discuss a specific Python problem or project?**\n",
      "*   **Learn about a new Python library or concept?**\n",
      "*   **Share something cool you've built with Python?**\n",
      "*   **Just chat about the awesomeness of Python in general?**\n",
      "\n",
      "I'm ready when you are! Let's dive into some Python goodness.\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm pytholic\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm pytholic\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm pytholic\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Haha, I love that! Welcome, fellow Pytholic! That's a fantastic way to describe a serious passion for Python.\n",
      "\n",
      "So, what's on your mind today in the world of Python? Are you working on a cool project, exploring a new library, wrestling with a tricky problem, or just want to chat about its awesomeness?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm pytholic\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://docs.langchain.com/oss/python/langchain/models#advanced-streaming-topics:streaming-events), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='The **San Francisco 49ers** are one of the most storied and successful franchises in', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 11, 'output_tokens': 1295, 'total_tokens': 1306, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1276}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=\" the National Football League (NFL). Here's a breakdown of what makes them a legendary team:\\n\\n### Basic Information\\n\\n*   **Location:** San Francisco Bay Area (their stadium is in Santa Clara, California).\\n*   **Division\", additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 49, 'output_tokens': 49, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=':** NFC West\\n*   **Colors:** Scarlet Red, Gold, White\\n*   **Nickname Origin:** The \"49ers\" refers to the prospectors who flocked to Northern California during the 1849 Gold Rush.\\n*', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=\"   **Home Stadium:** Levi's Stadium (since 2014)\\n\\n### History & Dynasties\\n\\nThe 49ers have a rich history marked by two dominant dynasty eras:\\n\\n1.  **The \", additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 46, 'output_tokens': 46, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content='1980s Dynasty (The Montana/Walsh Era):**\\n    *   **Key Figures:** Head Coach Bill Walsh (the architect of the revolutionary \"West Coast Offense\"), legendary quarterback Joe Montana, and iconic safety Ronnie Lott.', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 51, 'output_tokens': 51, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' Later, wide receiver Jerry Rice joined to complete one of the greatest offensive trios ever.\\n    *   **Success:** This era saw the 49ers win **four Super Bowls** (XVI, XIX, XXIII, XXIV) in a', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' nine-year span, establishing them as the team of the decade. Their innovative offense and stout defense set new standards for NFL excellence.\\n\\n2.  **The 1990s (The Young/Rice Era):**\\n    *   ', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=\"**Key Figures:** After Joe Montana's departure, quarterback Steve Young stepped in and proved to be an MVP-caliber player, continuing to connect with Jerry Rice.\\n    *   **Success:** The 49ers won their **fifth Super Bowl\", additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 51, 'output_tokens': 51, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content='** (XXIX) in 1994, solidifying their place as one of the most successful franchises in NFL history.\\n\\n### Super Bowl Appearances & Wins\\n\\n*   **Super Bowl Wins (5):** XVI,', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 48, 'output_tokens': 48, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' XIX, XXIII, XXIV, XXIX\\n*   **Super Bowl Losses (3):** XLVII, LIV, LVIII (most recently in 2020 and 2024)\\n*   **Total Super Bowl Appearances', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 52, 'output_tokens': 52, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=':** 8\\n\\n### Key Players & Legends\\n\\nThe 49ers boast an incredible list of Hall of Fame players and coaches:\\n\\n*   **Joe Montana (QB):** \"Joe Cool,\" one of the greatest quarterbacks of all time.\\n', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=\"*   **Jerry Rice (WR):** Widely considered the greatest wide receiver in NFL history.\\n*   **Steve Young (QB):** MVP and Super Bowl-winning quarterback who stepped out of Montana's shadow.\\n*\", additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 48, 'output_tokens': 48, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content='   **Ronnie Lott (S):** One of the most feared and respected defensive players ever.\\n*   **Bill Walsh (Coach):** Revolutionary offensive mind, architect of the West Coast Offense.\\n*   **Frank Gore (RB', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=\"):** The franchise's all-time leading rusher.\\n*   **Patrick Willis (LB):** Dominant middle linebacker of the 2000s/2010s.\\n*   **Dwight Clark (WR\", additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 51, 'output_tokens': 51, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content='):** Famous for \"The Catch\" in the 1981 NFC Championship.\\n*   **Roger Craig (RB):** First player to gain 1,000 rushing and 1,000 receiving yards in a', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' single season.\\n*   **Fred Warner (LB):** Current defensive leader and one of the best linebackers in the league.\\n*   **Nick Bosa (DE):** Dominant pass rusher, Defensive Player of the', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 48, 'output_tokens': 48, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' Year.\\n*   **George Kittle (TE):** One of the most dynamic tight ends in the NFL.\\n*   **Christian McCaffrey (RB):** Elite dual-threat running back, a key offensive weapon.\\n\\n', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 48, 'output_tokens': 48, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content='### Recent History (Shanahan/Lynch Era)\\n\\nUnder Head Coach Kyle Shanahan and General Manager John Lynch (since 2017), the 49ers have re-emerged as a perennial contender:\\n\\n*', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 48, 'output_tokens': 48, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=\"   They've built a team known for its strong defense, dominant run game, and innovative offensive schemes.\\n*   They reached Super Bowl LIV (2020) and Super Bowl LVIII (2024), losing both to\", additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 49, 'output_tokens': 49, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' the Kansas City Chiefs.\\n*   Key current players include Brock Purdy (QB), Christian McCaffrey (RB), George Kittle (TE), Deebo Samuel (WR), Brandon Aiyuk (WR), Nick Bosa (DE),', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' Fred Warner (LB), and Talanoa Hufanga (S).\\n\\n### Fanbase & Rivalries\\n\\n*   **The Faithful:** The 49ers have a passionate and loyal fanbase known as \"The Faithful.\"\\n*   **R', additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 51, 'output_tokens': 51, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=\"ivalries:** Key rivalries include their NFC West foes (Seattle Seahawks, Los Angeles Rams, Arizona Cardinals), and historical rivalries with teams like the Dallas Cowboys.\\n\\nThe San Francisco 49ers remain one of the NFL's most iconic\", additional_kwargs={}, response_metadata={'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 50, 'output_tokens': 50, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content=' franchises, consistently striving for their sixth Super Bowl title and adding to their already impressive legacy.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 0, 'output_token_details': {'reasoning': 0}, 'total_tokens': 19, 'output_tokens': 19, 'input_token_details': {'cache_read': 0}}, tool_call_chunks=[])}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--019c4261-c554-7f70-9d63-6ca7e51780d0', tool_calls=[], invalid_tool_calls=[], tool_call_chunks=[], chunk_position='last')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The San Francisco 49ers are one of the most storied and successful franchises in NFL history, known for their rich tradition, iconic players, and multiple Super Bowl championships.\n",
      "\n",
      "Here's a breakdown of the team:\n",
      "\n",
      "1.|  **Founding and Name Origin:**\n",
      "    *   **Founded:** 1946, as a charter member of the All-America Football Conference (AAFC). They joined the NFL in 1950 when the AAFC merged| with the NFL.\n",
      "    *   **Name:** \"49ers\" refers to the prospectors who arrived in Northern California during the 1849 Gold Rush.\n",
      "\n",
      "2.  **Home Stadium:**\n",
      "    *   **Current|:** Levi's Stadium in Santa Clara, California (opened 2014).\n",
      "    *   **Previous Iconic Stadium:** Candlestick Park (1971-2013), which was famous for its often| windy and chilly conditions.\n",
      "\n",
      "3.  **Team Colors & Logo:**\n",
      "    *   **Colors:** Scarlet (red), Gold, and White.\n",
      "    *   **Logo:** A stylized \"SF\" in gold with a red outline,| often placed within a white oval.\n",
      "\n",
      "4.  **Championships & Dynasties:**\n",
      "    *   The 49ers have won **5 Super Bowl championships**:\n",
      "        *   **Super Bowl XVI (1981| season):** Defeated the Cincinnati Bengals.\n",
      "        *   **Super Bowl XIX (1984 season):** Defeated the Miami Dolphins.\n",
      "        *   **Super Bowl XXIII (1988 season):|** Defeated the Cincinnati Bengals.\n",
      "        *   **Super Bowl XXIV (1989 season):** Defeated the Denver Broncos.\n",
      "        *   **Super Bowl XXIX (1994 season):** Def|eated the San Diego Chargers.\n",
      "    *   **The 1980s Dynasty:** This era is arguably their most famous, led by legendary coach Bill Walsh (who pioneered the \"West Coast Offense\"), quarterback Joe Montana, and| wide receiver Jerry Rice. They won four Super Bowls in the decade, establishing themselves as one of the greatest teams in NFL history.\n",
      "    *   **The 1990s Success:** After Montana, Steve Young took over at| quarterback and continued the winning tradition, securing another Super Bowl title.\n",
      "\n",
      "5.  **Iconic Players & Hall of Famers:**\n",
      "    The 49ers boast an incredible list of Hall of Fame players and coaches, including:\n",
      "    |*   **Joe Montana (QB):** \"Joe Cool,\" one of the greatest quarterbacks of all time.\n",
      "    *   **Jerry Rice (WR):** Widely considered the greatest wide receiver in NFL history.\n",
      "    *   **Steve| Young (QB):** Montana's successor, a two-time MVP and Super Bowl XXIX MVP.\n",
      "    *   **Ronnie Lott (S):** One of the most feared and dominant defensive backs ever.\n",
      "    *|   **Bill Walsh (Coach):** The architect of the 49ers dynasty and the West Coast Offense.\n",
      "    *   **Frank Gore (RB):** The franchise's all-time leading rusher.\n",
      "    *|   **Patrick Willis (LB):** A dominant middle linebacker in the modern era.\n",
      "    *   **Fred Dean (DE), Charles Haley (DE/LB), Bryant Young (DT), Terrell Owens (WR), Jimmy Johnson (DB|), Hugh McElhenny (RB), Y.A. Tittle (QB), Bob St. Clair (OT), Dave Wilcox (LB), Joe Perry (RB), Leo Nomellini (DT).**\n",
      "\n",
      "6.  **Recent History| & Current Status:**\n",
      "    *   After a period of rebuilding in the 2000s, the 49ers experienced a resurgence in the early 2010s under coach Jim Harbaugh, reaching three consecutive| NFC Championship games and Super Bowl XLVII (losing to the Baltimore Ravens).\n",
      "    *   Under current head coach Kyle Shanahan and General Manager John Lynch, the team has returned to consistent contention. They reached Super Bowl LIV (losing to the| Kansas City Chiefs) and Super Bowl LVIII (again losing to the Kansas City Chiefs), as well as multiple NFC Championship games.\n",
      "    *   **Key Current Players:** Nick Bosa (DE), Christian McCaffrey (RB),| Fred Warner (LB), George Kittle (TE), Deebo Samuel (WR), Trent Williams (OT), Brock Purdy (QB). They are known for a strong running game, a dominant defense, and an innovative offensive scheme.\n",
      "\n",
      "7|.  **Rivalries:**\n",
      "    *   **Los Angeles Rams:** A long-standing NFC West division rivalry.\n",
      "    *   **Seattle Seahawks:** An intense, more recent division rivalry that heated up in the 2010|s.\n",
      "    *   **Dallas Cowboys:** A historic rivalry, especially prominent in the 1980s and 90s, featuring classic playoff matchups (e.g., \"The Catch\").\n",
      "    *   **Green Bay Packers|:** Another team with a significant playoff history against the 49ers.\n",
      "\n",
      "The San Francisco 49ers remain one of the NFL's premier franchises, with a passionate fanbase (\"The Faithful\") and a legacy of excellence that continues to| this day.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- ðŸš€ API: http://127.0.0.1:2024\n",
    "- ðŸŽ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- ðŸ“š API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the **Studio UI** URL shown above.\n",
    "\n",
    "The LangGraph API  [supports editing graph state](https://docs.langchain.com/langsmith/add-human-in-the-loop). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce51f04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'graph_id': 'agent',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'agent',\n",
       "  'created_at': '2026-02-09T12:38:53.790947+00:00',\n",
       "  'updated_at': '2026-02-09T12:38:53.790947+00:00',\n",
       "  'version': 1,\n",
       "  'description': None},\n",
       " {'assistant_id': '6f6fce9a-b777-529d-9699-dd340ddec86c',\n",
       "  'graph_id': 'dynamic_breakpoints',\n",
       "  'config': {},\n",
       "  'context': {},\n",
       "  'metadata': {'created_by': 'system'},\n",
       "  'name': 'dynamic_breakpoints',\n",
       "  'created_at': '2026-02-09T12:34:34.111183+00:00',\n",
       "  'updated_at': '2026-02-09T12:34:34.111183+00:00',\n",
       "  'version': 1,\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's [stream `values`](https://docs.langchain.com/oss/python/langgraph/streaming#stream-graph-state), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '019c426a-d938-7e32-b4d7-63c92bf9a285', 'attempt': 1}, id=None)\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '316cc26c-bf96-42aa-874a-d5022c5cbe91'}]}, id=None)\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '316cc26c-bf96-42aa-874a-d5022c5cbe91'}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3, \"a\": 2}'}, '__gemini_function_call_thought_signatures__': {'3840d0a5-717f-41ad-9fe1-d52535481725': 'CoUCAb4+9vs+zibWQQVKBur1IGe5wxXY/PPTUUnTl7jPBEHVgp4Ocz9X9FNXfsMSnqyFch6ofBNLIknURFO4uZHuIbEUvx5TXoORpTQ8YMQxhXEFWddMMu1Pr1fXo1YnsIEOfEpszPJ505rZMD3U4Wq/oatZp9aAxjNQLRdkb5Qby4YBmrhCun9AWASDNA8YLoDv4MolwGVLrioqg2swarDKB7eLERYWO+BEiyfpsF3gbnIpjzR3DpZkFAhiR+XNDqtJUWgg22trwi3MYUf5vWSDQ9yvW/uD10yaHXJfHGpI5OolrCHrpLIi9gaxctIA12zsGwHkjTR9Am4G5UIW73sa9QJLfyxn'}}, 'response_metadata': {'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019c426a-de11-7cd2-96b5-cc274e2a6810-0', 'tool_calls': [{'name': 'multiply', 'args': {'b': 3, 'a': 2}, 'id': '3840d0a5-717f-41ad-9fe1-d52535481725', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 83, 'total_tokens': 252, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 65}}}]}, id=None)\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '316cc26c-bf96-42aa-874a-d5022c5cbe91'}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3, \"a\": 2}'}, '__gemini_function_call_thought_signatures__': {'3840d0a5-717f-41ad-9fe1-d52535481725': 'CoUCAb4+9vs+zibWQQVKBur1IGe5wxXY/PPTUUnTl7jPBEHVgp4Ocz9X9FNXfsMSnqyFch6ofBNLIknURFO4uZHuIbEUvx5TXoORpTQ8YMQxhXEFWddMMu1Pr1fXo1YnsIEOfEpszPJ505rZMD3U4Wq/oatZp9aAxjNQLRdkb5Qby4YBmrhCun9AWASDNA8YLoDv4MolwGVLrioqg2swarDKB7eLERYWO+BEiyfpsF3gbnIpjzR3DpZkFAhiR+XNDqtJUWgg22trwi3MYUf5vWSDQ9yvW/uD10yaHXJfHGpI5OolrCHrpLIi9gaxctIA12zsGwHkjTR9Am4G5UIW73sa9QJLfyxn'}}, 'response_metadata': {'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019c426a-de11-7cd2-96b5-cc274e2a6810-0', 'tool_calls': [{'name': 'multiply', 'args': {'b': 3, 'a': 2}, 'id': '3840d0a5-717f-41ad-9fe1-d52535481725', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 83, 'total_tokens': 252, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 65}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '6a4ddc66-73e7-46df-8c2f-044faa3c25b5', 'tool_call_id': '3840d0a5-717f-41ad-9fe1-d52535481725', 'artifact': None, 'status': 'success'}]}, id=None)\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '316cc26c-bf96-42aa-874a-d5022c5cbe91'}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3, \"a\": 2}'}, '__gemini_function_call_thought_signatures__': {'3840d0a5-717f-41ad-9fe1-d52535481725': 'CoUCAb4+9vs+zibWQQVKBur1IGe5wxXY/PPTUUnTl7jPBEHVgp4Ocz9X9FNXfsMSnqyFch6ofBNLIknURFO4uZHuIbEUvx5TXoORpTQ8YMQxhXEFWddMMu1Pr1fXo1YnsIEOfEpszPJ505rZMD3U4Wq/oatZp9aAxjNQLRdkb5Qby4YBmrhCun9AWASDNA8YLoDv4MolwGVLrioqg2swarDKB7eLERYWO+BEiyfpsF3gbnIpjzR3DpZkFAhiR+XNDqtJUWgg22trwi3MYUf5vWSDQ9yvW/uD10yaHXJfHGpI5OolrCHrpLIi9gaxctIA12zsGwHkjTR9Am4G5UIW73sa9QJLfyxn'}}, 'response_metadata': {'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019c426a-de11-7cd2-96b5-cc274e2a6810-0', 'tool_calls': [{'name': 'multiply', 'args': {'b': 3, 'a': 2}, 'id': '3840d0a5-717f-41ad-9fe1-d52535481725', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 83, 'total_tokens': 252, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 65}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '6a4ddc66-73e7-46df-8c2f-044faa3c25b5', 'tool_call_id': '3840d0a5-717f-41ad-9fe1-d52535481725', 'artifact': None, 'status': 'success'}, {'content': 'The product of 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019c426a-e31c-7580-9205-e5f6b0a015b8-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 200, 'output_tokens': 12, 'total_tokens': 212, 'input_token_details': {'cache_read': 0}}}]}, id=None)\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='c6e378a9-17e5-473c-915a-dae0a01ad985'\n",
      "=========================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 78, 'total_tokens': 247, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 60}}, 'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3, \"a\": 2}'}, '__gemini_function_call_thought_signatures__': {'71e83700-8f1d-4d76-914e-3135cb257325': 'CvwBAb4+9vupxqc3dawy+/2ydJAYozi5jbRtTuwczE0vFH7oAWTIypOwUFSXTDI4qk95S/EUI3f9awfQ/ZKu+X5+tm7mgQoa1U0RpK0LSBu9y28g3+sEUENFtg86KK/dLBHP7QKx2lWEQ6rGcQ22oBdYbvunSIIdNAnQwU90Sv6+gvbFB00468viNwO39A7y4zo2A+IuboMhz2gtxs/GYrxWx/ZmWcrVG4AHGLQXbC+B+0rrUapj9kk0WtUaVO2LFHOq5P7mIU97Xp+5Ek8WX3wZzzi7U7inc1qFGQcKuHulCq22JByl0EQGDhDooXNq875SWjFyFNqlncZxIBr7'}} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c426b-8f00-7b73-b881-778d4fb82fc7-0' tool_calls=[{'name': 'multiply', 'args': {'b': 3, 'a': 2}, 'id': '71e83700-8f1d-4d76-914e-3135cb257325', 'type': 'tool_call'}] invalid_tool_calls=[]\n",
      "=========================\n",
      "content='6' name='multiply' id='a1989cbb-8376-4635-8732-0ab79c89f15d' tool_call_id='71e83700-8f1d-4d76-914e-3135cb257325'\n",
      "=========================\n",
      "content='The answer is 6.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 200, 'output_tokens': 6, 'total_tokens': 206, 'input_token_details': {'cache_read': 0}}} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c426b-954e-7050-8134-df53acc5ee09-0' tool_calls=[] invalid_tool_calls=[]\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can  [use `messages` mode](https://docs.langchain.com/oss/python/langgraph/streaming#supported-stream-modes) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "<!--You can dig further into the types [~here~](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages) [here](https://docs.langchain.com/oss/python/langgraph/concepts/langgraph_server). -->\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 019c4271-6de2-7690-be71-2d29f70a40bd\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: 4f297797-b156-454c-8343-ab02cc20689c, Function: multiply, Arguments: {'b': 3, 'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: 4f297797-b156-454c-8343-ab02cc20689c, Function: multiply, Arguments: {'b': 3, 'a': 2}\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: 4f297797-b156-454c-8343-ab02cc20689c, Function: multiply, Arguments: {'b': 3, 'a': 2}\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: 68eeaee4-16d1-4e99-86a2-2f38acae0832, Function: divide, Arguments: {'a': 6, 'b': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: 68eeaee4-16d1-4e99-86a2-2f38acae0832, Function: divide, Arguments: {'a': 6, 'b': 2}\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: 68eeaee4-16d1-4e99-86a2-2f38acae0832, Function: divide, Arguments: {'a': 6, 'b': 2}\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n",
      "AI: [{'type': 'text', 'text': 'The result of multiplying', 'index': 0}]\n",
      "--------------------------------------------------\n",
      "AI: [{'type': 'text', 'text': 'The result of multiplying 2 and 3 is 6, and dividing 6 by 2', 'index': 0}]\n",
      "--------------------------------------------------\n",
      "AI: [{'type': 'text', 'text': 'The result of multiplying 2 and 3 is 6, and dividing 6 by 2 gives 3.', 'index': 0}]\n",
      "--------------------------------------------------\n",
      "AI: [{'type': 'text', 'text': 'The result of multiplying 2 and 3 is 6, and dividing 6 by 2 gives 3.', 'index': 0}]\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n",
      "AI: [{'type': 'text', 'text': 'The result of multiplying 2 and 3 is 6, and dividing 6 by 2 gives 3.', 'index': 0}]\n",
      "Response Metadata: Finish Reason - STOP\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3. Then divide the answer by 2.\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata and response_metadata.get(\"finish_reason\"):\n",
    "                    print(f\"Response Metadata: Finish Reason - {response_metadata['finish_reason']}\")                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "source": [
    "Trace: https://smith.langchain.com/public/483a45d3-b7f8-4405-9db7-4e57f96b0743/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

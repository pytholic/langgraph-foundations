{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c56ab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e813bc",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6967cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1:8b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaef988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-02-01T14:15:09.400367Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6999957417, 'load_duration': 3599175625, 'prompt_eval_count': 12, 'prompt_eval_duration': 3000580209, 'eval_count': 10, 'eval_duration': 381649585, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019c198e-9bb8-7db0-9913-72b898df055a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"pytholic\")\n",
    "msg = [msg]\n",
    "\n",
    "llm.invoke(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f653861",
   "metadata": {},
   "source": [
    "## Search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3679fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/d4txrj4d1hdb9jxkz_prd3fw0000gn/T/ipykernel_8472/775519368.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  search = TavilySearchResults(max_results=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "  'content': '# What is LangGraph?\\n\\n## Authors\\n\\nBryan Clark \\n\\nSenior Technology Advocate\\n\\n## LangGraph overview\\n\\nLangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences.\\n\\n## LLM integration in LangGraph [...] LangGraph workflow\\n\\nLangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. Within LangGraph, the “state” feature serves as a memory bank that records and tracks all the valuable information processed by the AI system. It’s similar to a digital notebook where the system captures and updates data as it moves through various stages of a workflow or graph analysis.',\n",
       "  'score': 0.94174546},\n",
       " {'title': 'LangGraph overview - Docs by LangChain',\n",
       "  'url': 'https://docs.langchain.com/oss/javascript/langgraph/overview',\n",
       "  'content': 'Trusted by companies shaping the future of agents— including Klarna, Replit, Elastic, and more— LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents.\\nLangGraph is very low-level, and focused entirely on agent orchestration. Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools.\\nWe will commonly use LangChain components throughout the documentation to integrate models and tools, but you don’t need to use LangChain to use LangGraph. If you are just getting started with agents or want a higher-level abstraction, we recommend you use LangChain’s agents that provide pre-built architectures for common LLM and tool-calling loops. [...] LangGraph is focused on the underlying capabilities important for agent orchestration: durable execution, streaming, human-in-the-loop, and more.',\n",
       "  'score': 0.9307171},\n",
       " {'title': 'LangGraph overview - Docs by LangChain',\n",
       "  'url': 'https://docs.langchain.com/oss/python/langgraph/overview',\n",
       "  'content': 'Trusted by companies shaping the future of agents— including Klarna, Replit, Elastic, and more— LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents.LangGraph is very low-level, and focused entirely on agent orchestration. Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools.We will commonly use LangChain components throughout the documentation to integrate models and tools, but you don’t need to use LangChain to use LangGraph. If you are just getting started with agents or want a higher-level abstraction, we recommend you use LangChain’s agents that provide pre-built architectures for common LLM and tool-calling [...] LangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n   Durable execution: Build agents that persist through failures and can run for extended periods, resuming from where they left off.\\n   Human-in-the-loop: Incorporate human oversight by inspecting and modifying agent state at any point.\\n   Comprehensive memory: Create stateful agents with both short-term working memory for ongoing reasoning and long-term memory across sessions.\\n   Debugging with LangSmith: Gain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics.',\n",
       "  'score': 0.92980474}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=3)\n",
    "\n",
    "search_docs = search.invoke(\"What is Langgraph?\")\n",
    "\n",
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89532f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
